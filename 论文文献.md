# 基线论文：DABNet

## 技术

#### **空洞卷积**

**目的：**

空洞卷积的提出就是为了替代*池化层*，因为传统的池化层在增加感受野的同时会*导致信息的损失*，所以在计算量相当的情况下，空洞卷积能够在保留信息的情况下提供足够的感受野

**弊端：**

存在感受野不连续、小尺度物体检测需要调整扩张率、整体计算量大的问题

**相关文献：**

[1] Understanding Convolution for Semantic Segmentation arXiv:1702.08502v3



### **上采样**

在语义分割领域中，对于输入的 *HxW* 的图像要求获得的预测图也是 *HxW* 的，因此会采用上采样的方式进行图像大小的恢复，其中经典的上采样方法包括 *双线性插值、转置卷积、反池化法*

* 双线性插值

  速度快，计算量小，但是效果不理想，且不可学习

* 转置卷积

  就是 *反卷积*，相比于双线性插值来说效果更好，但是速度不理想，计算量偏大

* 反池化

  就是池化的逆操作，在池化的时候记录下对应 *kernel* 的下标，在反池化的时候按照记录信息进行元素填写。



## 参考文献

#### ESPNet

提出

# 12.10

## SFNet

### 1.背景

语义分割主要是对场景进行解析，具有两大需求，即==高分辨率和深层语义==，但是这两个需求和卷积网络设计是矛盾的。

卷积网络通过下采样来扩大感受野从而获取深层语义特征，==深层语义特征靠近输出端但分辨率低，缺乏空间细节信息，而高分辨率特征靠经输入端但缺乏深层语义信息==。其两者的分割结果如下：

![image-20201210100754702](%E8%AE%BA%E6%96%87%E6%96%87%E7%8C%AE.assets/image-20201210100754702.png)

**FCN** 通过下采样和卷积层的堆叠从而获得深层语义特征，但是缺乏重要的边界信息，针对该弊端，其他方法通过**空洞卷积**生成具有强语义表示的特征图，并且保证边界信息。但是会**存在额外的计算**。

### 2.贡献

1. 针对高分辨率和深层语义的获取，提出FPN模块。**将深层信息上采样，与浅层信息逐元素地相加，从而构建了尺寸不同的特征金字塔结构**

   ![image-20201210101432721](%E8%AE%BA%E6%96%87%E6%96%87%E7%8C%AE.assets/image-20201210101432721.png)

2. 针对深层特征到浅层特征的引入可能存在无效传递，从而影响分割精度的情况，**学习具有不同分辨率的层之间的语义流**。

3. 提出了一种新颖的**基于流的对齐模块（FAM）**，以学习相邻级别的特征图之间的语义流，并有效地将高级特征传播到高分辨率的特征。

4. 利用**FAM**替换正常的**双线性插值**作为上采样操作。（实现高分辨率和低分辨率的特征对齐）

# 12.24

## Understanding Convolution for Semantic Segmentation

### 1.背景

针对语义分割再卷积上进行研究，从而提高分割的整体精度

### 2.贡献

1. 大多的网路在解码部门通过双线性插值来进行图像恢复，由于双线性不可学习，会损失大量信息，针对该问题提出*DUC*模块
2. 针对空洞卷积存在的感受野不连续、丢失邻近信息等问题，提出*HDC*模块

## Decoders Matter for Semantic Segmentation

### 1.背景

针对在编解码结构中，通过在最后一层通过*双线性插值*来恢复图像分辨率的弊端

### 2.贡献

1. 提出了一种基于数据的上采样(DUpsampling)来代替双线性采样(bilinear)，它利用了语义分割标签空间的冗余性，并能够从低分辨率的cnn输出中恢复像素级预测
2. 为了减少高级特征中的信息缺失，往往会对不同级别的特征层上采样到同样分辨率进行融合，但是级别越高越容易在上采样过程中添加噪声，该论文提出把所有级别的特征都下采样到最高级特征大小进行融合。